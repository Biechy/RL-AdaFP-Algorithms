{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T19:20:32.546682Z","iopub.status.busy":"2024-01-23T19:20:32.546268Z","iopub.status.idle":"2024-01-23T19:20:32.563101Z","shell.execute_reply":"2024-01-23T19:20:32.562025Z","shell.execute_reply.started":"2024-01-23T19:20:32.546652Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import matplotlib.pylab as pl\n","from matplotlib.colors import ListedColormap\n","np.set_printoptions(precision=3)\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{},"source":["# Comparaison en pratique avec les algorithmes classiques\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T19:20:33.511283Z","iopub.status.busy":"2024-01-23T19:20:33.510891Z","iopub.status.idle":"2024-01-23T19:20:33.552977Z","shell.execute_reply":"2024-01-23T19:20:33.551767Z","shell.execute_reply.started":"2024-01-23T19:20:33.511251Z"},"trusted":true},"outputs":[],"source":["class Maze():\n","    def __init__(self, width=30, height=30, gamma=.9):\n","        \"\"\"\n","        Same initialization as seen in class, except that we create a v0 and apply a pi_greedy to it\n","        \"\"\"\n","        self.width = width-1\n","        self.height = height-1\n","        maze_size = (height, width)\n","        start_cell = (0,0)\n","        target_cell = (height-1, width-1)\n","\n","        maze = np.random.binomial(1, p=.15, size=maze_size)\n","        maze[:round(2*height/3),round(width/4)] = 1\n","        maze[round(height/3):,round(3*width/4)] = 1\n","        chl = round(2*height/5)\n","        chu = round(3*height/5)\n","        cwl = round(2*width/5)\n","        cwu = round(3*width/5)\n","        maze[chl:chu,cwl:cwu] = np.random.binomial(1, p=.5, size=(chu-chl, cwu-cwl))\n","        maze[start_cell] = 0\n","        maze[target_cell] = 0\n","        self.maze = maze\n","        self.actions = [0,1,2,3]\n","        self.action_coordinates = {0: np.array([1,0]),# down\n","                            1: np.array([0,1]), # right\n","                            2: np.array([-1,0]), # up\n","                            3: np.array([0,-1])} # left\n","        self.action_arrows = ['↓', '→', '↑', '←']\n","\n","        ####ADDED####\n","        self.states = np.argwhere(maze != 1) #get all the states that are not walls\n","        self.gamma=gamma\n","        self.v0 = np.random.random((height, width))\n","        self.pi = self.pi_greedy(self.v0)\n","        #############\n","        self.plot(policy=self.pi, path=True)\n","\n","    def plot(self, policy=None, path=False):\n","        grid_size = self.maze.shape\n","        fig, ax = plt.subplots(figsize=(grid_size[1]+1, grid_size[0]+1))\n","        im = ax.imshow(self.maze, cmap='Greys', interpolation='nearest', extent=[0, grid_size[1], 0, grid_size[0]], alpha=1)\n","        ax.set_xticks(np.arange(0, grid_size[1]+1, 1), minor=True)\n","        ax.set_yticks(np.arange(0, grid_size[0]+1, 1), minor=True)\n","        ax.grid(which=\"minor\", color='black', linestyle='-', linewidth=1)\n","        ax.set_xticks([])\n","        ax.set_yticks([])\n","        if policy is not None:\n","            # Plot arrows\n","            for i in range(grid_size[0]):\n","                for j in range(grid_size[1]):\n","                    action = policy[i, j]\n","                    ax.text(j + 0.5, grid_size[0] - i - 0.5, self.action_arrows[action],\n","                            ha='center', va='center', fontsize=12, fontweight='bold')\n","            if path is True:\n","                cmap = pl.cm.Reds\n","                my_cmap = cmap(np.arange(cmap.N))\n","                my_cmap[:,-1] = np.linspace(0, 1, cmap.N)\n","                my_cmap = ListedColormap(my_cmap)\n","\n","                im = ax.imshow(self.path_array(policy), cmap=my_cmap, interpolation='nearest', extent=[0, grid_size[1], 0, grid_size[0]], alpha=.5)\n","        plt.show()\n","\n","    def path_array(self, policy):\n","        array = np.zeros((self.height+1, self.width+1), dtype=int)\n","        s = (0, 0)\n","        array[s] = 1\n","        while True :\n","            _, s_ = self.transition(s, policy[s])\n","            s_ = tuple(s_)\n","            if array[s_] == 1 : break\n","            array[s_] = 1\n","            if s_[0] == self.height and s_[1] == self.width : break\n","            s = s_\n","        return array\n","    \n","    def transition(self, s,a):\n","        \"\"\"\n","        Transition function of the maze\n","        \n","        Parameters\n","        ----------\n","        s : tuple\n","            State\n","        a : int\n","            Action\n","\n","        Returns\n","        -------\n","        (r, s_) : tuple\n","            r : reward\n","            s_ : next state\n","        \"\"\"\n","        s_ = s+self.action_coordinates[a]\n","        if not any(np.array_equal(state, s_) for state in self.states):\n","            return (0, s)\n","        \n","        else:\n","            if np.array_equal(s_, np.array([self.height, self.width])):\n","                return (1, s_)\n","            else:\n","                return (0, s_)\n","    \n","    def pi_greedy(self, v):\n","        \"\"\"\n","        Greedy policy for a given value function\n","        \n","        Parameters\n","        ----------\n","        v : array\n","            Value function\n","        \n","        Returns\n","        -------\n","        pi : array\n","            Greedy policy (array of actions)\n","        \"\"\"\n","        pi = np.zeros((self.height+1, self.width+1), dtype=int)\n","        for s in self.states:\n","            pi[tuple(s)] = np.argmax([r + self.gamma*v[tuple(s_)] for r, s_ in [self.transition(s,a) for a in self.actions]])\n","        return pi\n","\n","    def Bpi(self, v, pi):\n","        \"\"\"\n","        Bellman PI operator for a given value function and policy\n","\n","        Parameters\n","        ----------\n","        v : array\n","            Value function\n","        pi : array\n","            Policy (array of actions)\n","\n","        Returns\n","        -------\n","        v_ : array\n","            New value function\n","        \"\"\"\n","        v_ = np.zeros_like(v)\n","        for s in self.states:\n","            r, s_ = self.transition(s, pi[tuple(s)])\n","            v_[tuple(s)] = r+self.gamma*v[tuple(s_)]\n","        return v_\n","\n","    def Bstar(self, v, pi):\n","        \"\"\"\n","        Bellman Star operator for a given value function and policy\n","\n","        Parameters\n","        ----------\n","        v : array\n","            Value function\n","        pi (UNUSED) : array \n","            Policy (array of actions)\n","\n","        Returns\n","        -------\n","        v_ : array\n","            New value function\n","        \"\"\"\n","        v_ = np.zeros_like(v)\n","        for s in self.states:\n","            pi_s = np.argmax([r + self.gamma*v[tuple(s_)] for r, s_ in [self.transition(s,a) for a in self.actions]])\n","            r, s_ = self.transition(s, pi_s)\n","            v_[s] = r + self.gamma*v[s_]\n","        return v_\n","    \n","    def AdaVI(self, eta, B,  graph=False, espilon=1e-6, max_iter=1e3):\n","        \"\"\"\n","        Adaptive VI algorithm\n","        \n","        Parameters\n","        ----------\n","        eta : float\n","            Learning rate\n","        B : function\n","            Bellman operator\n","        graph : bool, optional\n","            If True, plot the convergence of the algorithm\n","        espilon : float, optional\n","            Convergence threshold\n","        max_iter : int, optional\n","            Maximum number of iterations\n","\n","        Returns\n","        -------\n","        norm_list : list\n","            List of the norm of the difference between the state-value function at each iteration and the optimal state-value function\n","        \"\"\"\n","        v_list = [] #list of v at each iteration\n","        sum_square = 0 #sum of the square of the difference between Bv and v\n","        norm_list = [] #list of the norm of the difference between Bv and v\n","        pi = self.pi\n","        v = self.v0\n","        for _ in range(int(max_iter)):\n","            diff = B(v,pi)-v\n","            sum_square += np.linalg.norm(diff)**2\n","            v_ = v + eta*(diff)/np.sqrt(sum_square)\n","            if np.amax(np.abs(diff)) < espilon:\n","                print(f'AdaVI converged for eta={eta}')\n","                break\n","            elif graph:\n","                norm_list.append(np.amax(np.abs(diff))) \n","                v_list.append(v_)\n","            v = v_.copy()\n","        else:\n","            print(f'AdaVI not converged for eta={eta}')\n","        \n","        if graph:\n","            plt.semilogy(range(len(norm_list)), norm_list, label=r'ADA-VI pour $\\eta$='+str(eta))\n","            return [np.amax(w-v_list[-1]) for w in v_list]\n","        \n","    \n","    def VI(self, B,  graph=False, espilon=1e-6, max_iter=1e6):\n","        \"\"\"\n","        Value Iteration algorithm\n","\n","        Parameters\n","        ----------\n","        B : function\n","            Bellman operator\n","        graph : bool, optional\n","            If True, plot the convergence of the algorithm\n","        espilon : float, optional\n","            Convergence threshold\n","        max_iter : int, optional\n","            Maximum number of iterations\n","\n","        Returns\n","        -------\n","        norm_list : list\n","            List of the norm of the difference between the state-value function at each iteration and the optimal state-value function\n","        \"\"\"\n","        v_list = [] #list of v at each iteration\n","        norm_list = [] #list of the norm of the difference between Bv and v\n","        pi = self.pi\n","        v = self.v0\n","        for _ in range(int(max_iter)):\n","            v_ = B(v,pi)\n","            if np.amax(v-v_) < espilon:\n","                print('VI converged')\n","                break\n","            elif graph:\n","                norm_list.append(np.amax(v-v_))\n","                v_list.append(v_)\n","            v = v_.copy()\n","        else:\n","            print('VI not converged')\n","        \n","        if graph:\n","            plt.semilogy(range(len(norm_list)), norm_list, label=r'VI')\n","            return [np.amax(w-v_list[-1]) for w in v_list]\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T14:09:05.410072Z","iopub.status.busy":"2024-01-23T14:09:05.409814Z","iopub.status.idle":"2024-01-23T14:09:06.046025Z","shell.execute_reply":"2024-01-23T14:09:06.045079Z","shell.execute_reply.started":"2024-01-23T14:09:05.410051Z"},"trusted":true},"outputs":[],"source":["np.random.seed(420)\n","maze = Maze(10,10)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T14:09:06.048288Z","iopub.status.busy":"2024-01-23T14:09:06.048019Z","iopub.status.idle":"2024-01-23T14:10:09.881241Z","shell.execute_reply":"2024-01-23T14:10:09.880313Z","shell.execute_reply.started":"2024-01-23T14:09:06.048264Z"},"trusted":true},"outputs":[],"source":["v_list = []\n","etas = [.7, 1, 3, 5, 7, 10, 50, 100]\n","plt.figure(figsize=(12, 5))\n","plt.subplot(1, 2, 1)\n","for eta in etas:\n","    v_list.append(maze.AdaVI(eta, maze.Bpi, graph=True))\n","v_list.append(maze.VI(maze.Bpi, graph=True))\n","plt.ylabel(r'$||v_k- B_\\pi v_k||_\\infty$ (log)')\n","plt.xlabel('Nombre d\\'itérations')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","for i, eta in enumerate(etas):\n","    plt.semilogy(range(len(v_list[i])), v_list[i], label=r'ADA-VI, $\\eta=$'+str(eta))\n","plt.semilogy(range(len(v_list[-1])), v_list[-1], label=r'VI')\n","plt.legend()\n","plt.ylabel(r'$||v_k- v_\\pi||_\\infty$ (log)')\n","plt.xlabel('Nombre d\\'itérations')\n","plt.suptitle(r'Comparaison de convergence de Ada-VI$^{(V)}_\\pi$ et VI$^{(V)}_\\pi$')\n","plt.tight_layout()\n","plt.subplots_adjust(wspace=0.4)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T14:10:09.882638Z","iopub.status.busy":"2024-01-23T14:10:09.882337Z","iopub.status.idle":"2024-01-23T14:14:57.421312Z","shell.execute_reply":"2024-01-23T14:14:57.420375Z","shell.execute_reply.started":"2024-01-23T14:10:09.882612Z"},"trusted":true},"outputs":[],"source":["v_list = []\n","etas = [.7, 1, 3, 5, 7, 10, 50, 100]\n","plt.figure(figsize=(12, 5))\n","plt.subplot(1, 2, 1)\n","for eta in etas:\n","    v_list.append(maze.AdaVI(eta, maze.Bstar, graph=True))\n","v_list.append(maze.VI(maze.Bstar, graph=True))\n","plt.ylabel(r'$||v_k- B_* v_k||_\\infty$ (log)')\n","plt.xlabel('Nombre d\\'itérations')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","for i, eta in enumerate(etas):\n","    plt.semilogy(range(len(v_list[i])), v_list[i], label=r'ADA-VI, $\\eta=$'+str(eta))\n","plt.semilogy(range(len(v_list[-1])), v_list[-1], label=r'VI')\n","plt.legend()\n","plt.ylabel(r'$||v_k- v_*||_\\infty$ (log)')\n","plt.xlabel('Nombre d\\'itérations')\n","plt.suptitle(r'Comparaison de convergence de Ada-VI$^{(V)}_*$ et VI$^{(V)}_*$')\n","plt.tight_layout()\n","plt.subplots_adjust(wspace=0.4)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Extensions\n"]},{"cell_type":"markdown","metadata":{},"source":["## Itérations de fonctions action-valeur\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T14:14:57.422715Z","iopub.status.busy":"2024-01-23T14:14:57.422365Z","iopub.status.idle":"2024-01-23T14:14:57.440074Z","shell.execute_reply":"2024-01-23T14:14:57.439114Z","shell.execute_reply.started":"2024-01-23T14:14:57.422686Z"},"trusted":true},"outputs":[],"source":["class Maze_Actions(Maze):\n","    def __init__(self, width=30, height=30, gamma=.9, subsets=5):\n","        super().__init__(width, height, gamma)\n","        self.q0 = np.array([np.random.random((height, width)) for _ in self.actions])\n","\n","    def AdaVI_action(self, eta, B, graph=False, espilon=1e-6, max_iter=1e3):\n","        \"\"\"\n","        Adaptive VI algorithm for action-value functions\n","\n","        Parameters\n","        ----------\n","        eta : float\n","            Learning rate\n","        B : function\n","            Bellman operator\n","        graph : bool, optional\n","            If True, plot the convergence of the algorithm\n","        espilon : float, optional\n","            Convergence threshold\n","        max_iter : int, optional\n","            Maximum number of iterations\n","\n","        Returns\n","        -------\n","        norm_list : list\n","            List of the norm of the difference between the action-value function at each iteration and the optimal action-value function\n","        \"\"\"\n","        q_list = [] #list of q at each iteration\n","        sum_square = 0 #sum of the square of the difference between Bq and q\n","        norm_list = [] #list of the norm of the difference between Bq and q\n","        pi = self.pi\n","        q = self.q0\n","        for _ in range(int(max_iter)):\n","            diff = B(q,pi)-q\n","            sum_square += np.linalg.norm(diff)**2\n","            q_ = q + eta*(diff)/np.sqrt(sum_square)\n","            if np.amax(np.abs(diff)) < espilon:\n","                print(f'AdaVI converged for eta={eta}')\n","                break\n","            elif graph:\n","                norm_list.append(np.amax(np.abs(diff)))  \n","                q_list.append(q_)\n","            q = q_.copy()\n","        else:\n","            print(f'AdaVI not converged for eta={eta}')\n","        \n","        if graph:\n","            plt.semilogy(range(len(norm_list)), norm_list, label=r'ADA-VI pour $\\eta=$'+str(eta))\n","            return [np.amax(p-q_list[-1]) for p in q_list]\n","            \n","        return q_list\n","            \n","    def VI_action(self, B, graph=False, espilon=1e-6, max_iter=1e3):\n","        \"\"\"\n","        Value Iteration algorithm for action-value functions\n","\n","        Parameters\n","        ----------\n","        B : function\n","            Bellman operator\n","        graph : bool, optional\n","            If True, plot the convergence of the algorithm\n","        espilon : float, optional\n","            Convergence threshold\n","        max_iter : int, optional\n","            Maximum number of iterations\n","\n","        Returns\n","        -------\n","        norm_list : list\n","            List of the norm of the difference between the action-value function at each iteration and the optimal action-value function\n","        \"\"\"\n","        q_list = [] #list of q at each iteration\n","        norm_list = [] #list of the norm of the difference between Bq and q\n","        pi = self.pi\n","        q = self.q0\n","        for _ in range(int(max_iter)):\n","            q_ = B(q,pi)\n","            if np.amax(np.abs(q_-q)) < espilon:\n","                print(f'VI converged')\n","                break\n","            elif graph:\n","                norm_list.append(np.amax(np.abs(q_-q))) \n","                q_list.append(q_)\n","            q = q_.copy()\n","        else:\n","            print(f'VI not converged')\n","        \n","        if graph:\n","            plt.semilogy(range(len(norm_list)), norm_list, label=r'VI')\n","            return [np.amax(p-q_list[-1]) for p in q_list]\n","    \n","    def Bpi_action(self, q, pi):\n","        \"\"\"\n","        Bellman PI operator for action-value functions\n","\n","        Parameters\n","        ----------\n","        q : array\n","            Action-value function\n","        pi : array\n","            Policy (array of actions)\n","\n","        Returns\n","        -------\n","        q_ : array\n","            New action-value function\n","        \"\"\"\n","        q_ = np.zeros_like(q)\n","        for s in self.states:\n","            for a in self.actions:\n","                r, s_ = self.transition(s, a)\n","                q_[a][tuple(s)] = r + self.gamma*q[pi[tuple(s_)]][tuple(s_)]\n","        return q_\n","    \n","    def Bstar_action(self, q, pi):\n","        \"\"\"\n","        Bellman Star operator for action-value functions\n","\n","        Parameters\n","        ----------\n","        q : array\n","            Action-value function\n","        pi (UNUSED) : array\n","            Policy (array of actions)\n","\n","        Returns\n","        -------\n","        q_ : array\n","            New action-value function\n","        \"\"\"\n","        q_ = np.zeros_like(q)\n","        for s in self.states:\n","            for a in self.actions:\n","                r, s_ = self.transition(s, a)\n","                q_[a][tuple(s)] = r+self.gamma*np.max([q[a_][tuple(s_)] for a_ in self.actions])\n","        return q_"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T14:14:57.441408Z","iopub.status.busy":"2024-01-23T14:14:57.441137Z","iopub.status.idle":"2024-01-23T14:14:58.023784Z","shell.execute_reply":"2024-01-23T14:14:58.022882Z","shell.execute_reply.started":"2024-01-23T14:14:57.441375Z"},"trusted":true},"outputs":[],"source":["np.random.seed(420)\n","maze_actions = Maze_Actions(10,10)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T14:14:58.025169Z","iopub.status.busy":"2024-01-23T14:14:58.024901Z","iopub.status.idle":"2024-01-23T14:16:59.908918Z","shell.execute_reply":"2024-01-23T14:16:59.908033Z","shell.execute_reply.started":"2024-01-23T14:14:58.025144Z"},"trusted":true},"outputs":[],"source":["q_list = []\n","etas = [3, 5, 7, 10, 50]\n","plt.figure(figsize=(12, 5))\n","plt.subplot(1, 2, 1)\n","for eta in etas:\n","    q_list.append(maze_actions.AdaVI_action(eta, maze_actions.Bpi_action, graph=True))\n","q_list.append(maze_actions.VI_action(maze_actions.Bpi_action, graph=True))\n","plt.ylabel(r'$||q_k- B_\\pi q_k||_\\infty$ (log)')\n","plt.xlabel('Nombre d\\'itérations')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","for i, eta in enumerate(etas):\n","    plt.semilogy(range(len(q_list[i])), q_list[i], label=r'ADA-VI, $\\eta=$'+str(eta))\n","plt.semilogy(range(len(q_list[-1])), q_list[-1], label=r'VI')\n","plt.legend()\n","plt.ylabel(r'$||q_k- q_\\pi||_\\infty$ (log)')\n","plt.xlabel('Nombre d\\'itérations')\n","plt.suptitle(r'Comparaison de convergence de Ada-VI$^{(Q)}_\\pi$ et VI$^{(Q)}_\\pi$')\n","plt.tight_layout()\n","plt.subplots_adjust(wspace=0.4)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T14:16:59.910178Z","iopub.status.busy":"2024-01-23T14:16:59.909933Z","iopub.status.idle":"2024-01-23T14:19:10.099674Z","shell.execute_reply":"2024-01-23T14:19:10.098802Z","shell.execute_reply.started":"2024-01-23T14:16:59.910155Z"},"trusted":true},"outputs":[],"source":["q_list = []\n","etas = [3, 5, 7, 10, 50]\n","plt.figure(figsize=(12, 5))\n","plt.subplot(1, 2, 1)\n","for eta in etas:\n","    q_list.append(maze_actions.AdaVI_action(eta, maze_actions.Bstar_action, graph=True))\n","q_list.append(maze_actions.VI_action(maze_actions.Bstar_action, graph=True))\n","plt.ylabel(r'$||q_k- B_* q_k||_\\infty$ (log)')\n","plt.xlabel('Nombre d\\'itérations')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","for i, eta in enumerate(etas):\n","    plt.semilogy(range(len(q_list[i])), q_list[i], label=r'ADA-VI, $\\eta=$'+str(eta))\n","plt.plot(range(len(q_list[-1])), q_list[-1], label=r'VI')\n","plt.legend()\n","plt.ylabel(r'$||q_k- q_*||_\\infty$ (log)')\n","plt.xlabel('Nombre d\\'itérations')\n","plt.suptitle(r'Comparaison de convergence de Ada-VI$^{(Q)}_*$ et VI$^{(Q)}_*$')\n","plt.tight_layout()\n","plt.subplots_adjust(wspace=0.4)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Itérations asynchrones\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T19:20:45.983322Z","iopub.status.busy":"2024-01-23T19:20:45.982967Z","iopub.status.idle":"2024-01-23T19:20:46.000174Z","shell.execute_reply":"2024-01-23T19:20:45.998900Z","shell.execute_reply.started":"2024-01-23T19:20:45.983294Z"},"trusted":true},"outputs":[],"source":["class Maze_Asynch(Maze):\n","    def __init__(self, width=30, height=30, gamma=.9, subsets=5):\n","        super().__init__(width, height, gamma)\n","        self.subsets=np.array_split(np.argwhere(self.maze != 2), subsets) #on all states because if the wall is not updated, the infinite norm of v-Bv become a constant\n","    \n","    def AdaVI_asynch(self, eta, B, graph=False, espilon=1e-6, max_iter=1e3):\n","        \"\"\"\n","        Adaptive VI algorithm with asynchronous updates\n","        Be careful, one iteration is one update of all components of the state-value function.\n","\n","        Parameters\n","        ----------\n","        eta : float\n","            Learning rate\n","        B : function\n","            Bellman operator\n","        graph : bool, optional\n","            If True, plot the convergence of the algorithm\n","        espilon : float, optional\n","            Convergence threshold\n","        max_iter : int, optional\n","            Maximum number of iterations\n","        \n","        Returns\n","        -------\n","        norm_list : list\n","            List of the norm of the difference between the state-value function at each iteration and the optimal state-value function\n","        \"\"\"\n","        v_list = [] #list of v at each iteration\n","        sum_square = 0 #sum of the square of the difference between Bv and v\n","        norm_list = []  #list of the norm of the difference between Bv and v\n","        pi = self.pi\n","        v = self.v0\n","        for _ in range(int(max_iter)):\n","            v_ = v.copy()\n","            sum_square += np.linalg.norm(B(v_,pi)-v_)**2\n","            for subset in self.subsets:\n","                diff = B(v_,pi)-v_\n","                for s in subset:\n","                    v_[tuple(s)] = v[tuple(s)] + eta*(diff[tuple(s)])/np.sqrt(sum_square)\n","            if np.amax(np.abs(diff)) < espilon:\n","                print(f'AdaVI converged for eta={eta}')\n","                break\n","            elif graph:\n","                norm_list.append(np.amax(np.abs(diff)))\n","                v_list.append(v_)\n","            v = v_\n","        else:\n","            print(f'AdaVI not converged for eta={eta}')\n","        \n","        if graph:\n","            plt.semilogy(range(len(norm_list)), norm_list, label=r'ADA-VI asynch, $\\eta=$'+str(eta))\n","            return [np.amax(w-v_list[-1]) for w in v_list]\n","            \n","    def VI_asynch(self, B, graph=False, espilon=1e-6, max_iter=1e3):\n","        \"\"\"\n","        Value Iteration algorithm with asynchronous updates\n","        Be careful, one iteration is one update of all components of the state-value function.\n","\n","        Parameters\n","        ----------\n","        B : function\n","            Bellman operator\n","        graph : bool, optional\n","            If True, plot the convergence of the algorithm\n","        espilon : float, optional\n","            Convergence threshold\n","        max_iter : int, optional\n","            Maximum number of iterations\n","\n","        Returns\n","        -------\n","        norm_list : list\n","            List of the norm of the difference between the state-value function at each iteration and the optimal state-value function\n","        \"\"\"\n","        v_list = [] #list of v at each iteration\n","        norm_list = [] #list of the norm of the difference between Bv and v\n","        pi = self.pi\n","        v = self.v0\n","        for _ in range(int(max_iter)):\n","            v_ = v.copy()\n","            for subset in self.subsets:\n","                B_ = B(v_, pi)\n","                for s in subset:\n","                    v_[tuple(s)] = B_[tuple(s)]\n","            if np.amax(np.abs(v_-v)) < espilon:\n","                print(f'VI converged')\n","                break\n","            elif graph:\n","                norm_list.append(np.amax(np.abs(v_-v))) \n","                v_list.append(v_)\n","            v = v_\n","        else:\n","            print(f'VI not converged')\n","        \n","        if graph:\n","            plt.semilogy(range(len(norm_list)), norm_list, label=r'VI asynch')\n","            return [np.amax(w-v_list[-1]) for w in v_list]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T19:20:47.791737Z","iopub.status.busy":"2024-01-23T19:20:47.790948Z","iopub.status.idle":"2024-01-23T19:20:48.495323Z","shell.execute_reply":"2024-01-23T19:20:48.494213Z","shell.execute_reply.started":"2024-01-23T19:20:47.791695Z"},"trusted":true},"outputs":[],"source":["np.random.seed(420)\n","maze_asynch = Maze_Asynch(10, 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T19:20:50.820273Z","iopub.status.busy":"2024-01-23T19:20:50.819881Z","iopub.status.idle":"2024-01-23T19:23:14.756284Z","shell.execute_reply":"2024-01-23T19:23:14.755100Z","shell.execute_reply.started":"2024-01-23T19:20:50.820243Z"},"trusted":true},"outputs":[],"source":["v_list = []\n","etas = [3, 5, 7, 10, 50]\n","plt.figure(figsize=(12, 5))\n","plt.subplot(1, 2, 1)\n","for eta in etas:\n","    v_list.append(maze_asynch.AdaVI_asynch(eta, maze_asynch.Bpi, graph=True))\n","v_list.append(maze_asynch.VI_asynch(maze_asynch.Bpi, graph=True))\n","plt.ylabel(r'$||v_k- B_\\pi v_k||_\\infty$ (log)')\n","plt.xlabel('Nombre d\\'itérations')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","for i, eta in enumerate(etas):\n","    plt.semilogy(range(len(v_list[i])), v_list[i], label=r'ADA-VI asynch, $\\eta=$'+str(eta))\n","plt.semilogy(range(len(v_list[-1])), v_list[-1], label=r'VI asynch')\n","plt.legend()\n","plt.ylabel(r'$||v_k- v_\\pi||_\\infty$ (log)')\n","plt.xlabel('Nombre d\\'itérations')\n","plt.suptitle(r'Comparaison de convergence de Ada-VI$^{(V)}_\\pi$ et VI$^{(V)}_\\pi$ asynchrone')\n","plt.tight_layout()\n","plt.subplots_adjust(wspace=0.4)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T19:23:14.758315Z","iopub.status.busy":"2024-01-23T19:23:14.757994Z","iopub.status.idle":"2024-01-23T19:31:45.601804Z","shell.execute_reply":"2024-01-23T19:31:45.600431Z","shell.execute_reply.started":"2024-01-23T19:23:14.758270Z"},"trusted":true},"outputs":[],"source":["v_list = []\n","etas = [3, 5, 7, 10, 50]\n","plt.figure(figsize=(12, 5))\n","plt.subplot(1, 2, 1)\n","for eta in etas:\n","    v_list.append(maze_asynch.AdaVI_asynch(eta, maze_asynch.Bstar, graph=True))\n","v_list.append(maze_asynch.VI_asynch(maze_asynch.Bstar, graph=True))\n","plt.ylabel(r'$||v_k- B_\\pi v_k||_\\infty$ (log)')\n","plt.xlabel('Nombre d\\'itérations')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","for i, eta in enumerate(etas):\n","    plt.semilogy(range(len(v_list[i])), v_list[i], label=r'ADA-VI asynch, $\\eta=$'+str(eta))\n","plt.semilogy(range(len(v_list[-1])), v_list[-1], label=r'VI asynch')\n","plt.legend()\n","plt.ylabel(r'$||v_k- v_*||_\\infty$ (log)')\n","plt.xlabel('Nombre d\\'itérations')\n","plt.suptitle(r'Comparaison de convergence de Ada-VI$^{(V)}_*$ et VI$^{(V)}_*$ asynchrone')\n","plt.tight_layout()\n","plt.subplots_adjust(wspace=0.4)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Composante par composante\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T14:19:10.103749Z","iopub.status.busy":"2024-01-23T14:19:10.103165Z","iopub.status.idle":"2024-01-23T14:19:10.118060Z","shell.execute_reply":"2024-01-23T14:19:10.117150Z","shell.execute_reply.started":"2024-01-23T14:19:10.103713Z"},"trusted":true},"outputs":[],"source":["class Maze_Component(Maze):\n","    def __init__(self, width=30, height=30, gamma=.9, subsets=5):\n","        super().__init__(width, height, gamma)\n","\n","    def AdaVI_component(self, eta, B,  graph=False, espilon=1e-6, max_iter=1e3):\n","        \"\"\"\n","        Adaptive VI algorithm for component per component of the state-value function.\n","        Be careful, one iteration is one update of all components of the state-value function.\n","\n","        Parameters\n","        ----------\n","        eta : float\n","            Learning rate\n","        B : function\n","            Bellman operator\n","        graph : bool, optional\n","            If True, plot the convergence of the algorithm\n","        espilon : float, optional\n","            Convergence threshold\n","        max_iter : int, optional\n","            Maximum number of iterations\n","\n","        Returns\n","        -------\n","        norm_list : list\n","            List of the norm of the difference between the state-value function at each iteration and the optimal state-value function\n","        \"\"\"\n","        v_list = [] #list of v at each iteration\n","        norm_list = [] #list of the norm of the difference between Bv and v\n","        pi = self.pi\n","        v = self.v0\n","        sum_square = np.zeros_like(v) #matrix sum of the square of the matrix difference between Bv and v\n","        for _ in range(int(max_iter)):\n","            v_ = v.copy()\n","            for s in np.argwhere(self.maze != 2): #on all states because if the wall is not updated, the infinite norm of v-Bv become a constant\n","                diff = B(v_,pi)-v_\n","                sum_square += (diff)**2\n","                v_[tuple(s)] = v[tuple(s)] + eta*(diff[tuple(s)])/np.sqrt(sum_square[tuple(s)])\n","            if np.amax(np.abs(diff)) < espilon:\n","                print(f'AdaVI converged for eta={eta}')\n","                break\n","            elif graph:\n","                norm_list.append(np.amax(np.abs(diff)))\n","                v_list.append(v_)\n","            v = v_.copy()\n","        else:\n","            print(f'AdaVI not converged for eta={eta}')\n","        \n","        if graph:\n","            plt.semilogy(range(len(norm_list)), norm_list, label=r'ADA-VI component, $\\eta=$'+str(eta))\n","            return [np.amax(w-v_list[-1]) for w in v_list]\n","            \n","    def VI_component(self, B,  graph=False, espilon=1e-6, max_iter=1e3):\n","        \"\"\"\n","        Value Iteration algorithm for component per component of the state-value function.\n","        Be careful, one iteration is one update of all components of the state-value function.\n","\n","        Parameters\n","        ----------\n","        B : function\n","            Bellman operator\n","        graph : bool, optional\n","            If True, plot the convergence of the algorithm\n","        espilon : float, optional\n","            Convergence threshold\n","        max_iter : int, optional\n","            Maximum number of iterations\n","        \n","        Returns\n","        -------\n","        norm_list : list\n","            List of the norm of the difference between the state-value function at each iteration and the optimal state-value function\n","        \"\"\"\n","        v_list = [] #list of v at each iteration\n","        norm_list = [] #list of the norm of the difference between Bv and v\n","        pi = self.pi\n","        v = self.v0\n","        for _ in range(int(max_iter)):\n","            v_ = v.copy()\n","            for s in np.argwhere(self.maze != 2): #on all states because if the wall is not updated, the infinite norm of v-Bv become a constant\n","                v_[tuple(s)] = B(v_,pi)[tuple(s)]\n","            if np.amax(np.abs(v_-v)) < espilon:\n","                print(f'VI converged')\n","                break\n","            elif graph:\n","                norm_list.append(np.amax(np.abs(v_-v)))\n","                v_list.append(v_)\n","            v = v_\n","        else:\n","            print(f'VI not converged')\n","        \n","        if graph:\n","            plt.semilogy(range(len(norm_list)), norm_list, label=r'VI component')\n","            return [np.amax(w-v_list[-1]) for w in v_list]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T14:19:10.119454Z","iopub.status.busy":"2024-01-23T14:19:10.119202Z","iopub.status.idle":"2024-01-23T14:19:10.646628Z","shell.execute_reply":"2024-01-23T14:19:10.645715Z","shell.execute_reply.started":"2024-01-23T14:19:10.119431Z"},"trusted":true},"outputs":[],"source":["np.random.seed(420)\n","maze_component = Maze_Component(10, 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T14:19:10.647960Z","iopub.status.busy":"2024-01-23T14:19:10.647701Z","iopub.status.idle":"2024-01-23T16:03:13.509719Z","shell.execute_reply":"2024-01-23T16:03:13.508757Z","shell.execute_reply.started":"2024-01-23T14:19:10.647937Z"},"trusted":true},"outputs":[],"source":["v_list = []\n","etas = [3, 5, 7, 10, 50]\n","plt.figure(figsize=(12, 5))\n","plt.subplot(1, 2, 1)\n","for eta in etas:\n","    v_list.append(maze_component.AdaVI_component(eta, maze_component.Bpi, graph=True))\n","v_list.append(maze_component.VI_component(maze_component.Bpi, graph=True))\n","plt.ylabel(r'$||v_k- B_\\pi v_k||_\\infty$ (log)')\n","plt.xlabel('Nombre d\\'itérations')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","for i, eta in enumerate(etas):\n","    plt.semilogy(range(len(v_list[i])), v_list[i], label=r'ADA-VI component, $\\eta=$'+str(eta))\n","plt.semilogy(range(len(v_list[-1])), v_list[-1], label=r'VI component')\n","plt.legend()\n","plt.ylabel(r'$||v_k- v_\\pi||_\\infty$ (log)')\n","plt.xlabel('Nombre d\\'itérations')\n","plt.suptitle(r'Comparaison de convergence de Ada-VI$^{(V)}_\\pi$ et VI$^{(V)}_\\pi$ composante par composante')\n","plt.tight_layout()\n","plt.subplots_adjust(wspace=0.4)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-23T17:52:00.762347Z","iopub.status.busy":"2024-01-23T17:52:00.761809Z","iopub.status.idle":"2024-01-23T17:52:06.424756Z","shell.execute_reply":"2024-01-23T17:52:06.423005Z","shell.execute_reply.started":"2024-01-23T17:52:00.762308Z"},"trusted":true},"outputs":[],"source":["v_list = []\n","etas = [3, 5, 7, 10, 50]\n","plt.figure(figsize=(12, 5))\n","plt.subplot(1, 2, 1)\n","for eta in etas:\n","    v_list.append(maze_component.AdaVI_component(eta, maze_component.Bstar, graph=True))\n","v_list.append(maze_component.VI_component(maze_component.Bstar, graph=True))\n","plt.ylabel(r'$||v_k- B_* v_k||_\\infty$ (log)')\n","plt.xlabel('Nombre d\\'itérations')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","for i, eta in enumerate(etas):\n","    plt.semilogy(range(len(v_list[i])), v_list[i], label=r'ADA-VI component, $\\eta=$'+str(eta))\n","plt.semilogy(range(len(v_list[-1])), v_list[-1], label=r'VI component')\n","plt.legend()\n","plt.ylabel(r'$||v_k- v_*||_\\infty$ (log)')\n","plt.xlabel('Nombre d\\'itérations')\n","plt.suptitle(r'Comparaison de convergence de Ada-VI$^{(V)}_*$ et VI$^{(V)}_*$ composante par composante')\n","plt.tight_layout()\n","plt.subplots_adjust(wspace=0.4)\n","plt.show()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30636,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
